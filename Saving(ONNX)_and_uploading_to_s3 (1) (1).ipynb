{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "871e8adf-ddf6-4664-abb9-020647b4c484",
   "metadata": {},
   "source": [
    "## Saving a trained model from PyTorch to ONNX format and upload the file to an S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8f3ad6a-9741-4276-afe7-452e338e7625",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your Hugging Face access token:  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\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.9/site-packages/transformers/models/auto/tokenization_auto.py:810: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.9/site-packages/transformers/models/auto/auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "998d37eaaa9b41858d3d11c262ba1d83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 'meta-llama/Llama-2-7b-hf' and tokenizer successfully loaded locally.\n",
      "Epoch 1/10: Train Loss = 2.3556, Validation Loss = 1.0875, Validation Accuracy = 0.5304\n",
      "Epoch 2/10: Train Loss = 1.0120, Validation Loss = 0.9504, Validation Accuracy = 0.6261\n",
      "Epoch 3/10: Train Loss = 0.8020, Validation Loss = 0.8709, Validation Accuracy = 0.6435\n",
      "Epoch 4/10: Train Loss = 0.7303, Validation Loss = 0.8053, Validation Accuracy = 0.6348\n",
      "Epoch 5/10: Train Loss = 0.7298, Validation Loss = 0.9113, Validation Accuracy = 0.6087\n",
      "Epoch 6/10: Train Loss = 0.7081, Validation Loss = 0.6856, Validation Accuracy = 0.6609\n",
      "Epoch 7/10: Train Loss = 0.6772, Validation Loss = 0.7526, Validation Accuracy = 0.6870\n",
      "Epoch 8/10: Train Loss = 0.7427, Validation Loss = 0.6779, Validation Accuracy = 0.6957\n",
      "Epoch 9/10: Train Loss = 0.6783, Validation Loss = 0.7930, Validation Accuracy = 0.6522\n",
      "Epoch 10/10: Train Loss = 0.6341, Validation Loss = 0.6262, Validation Accuracy = 0.6696\n",
      "Training complete. To view TensorBoard, run the following command:\n",
      "tensorboard --logdir=logs/training/2024-12-06_13:12:50\n",
      "ONNX model exported successfully and saved at './meta-llama-7b_model.onnx'.\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries and packages\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Hugging Face Authentication and Model Download\n",
    "def authenticate_and_download_model(model_name: str):\n",
    "    \"\"\"\n",
    "    Authenticate Hugging Face user and download the specified model locally.\n",
    "    \"\"\"\n",
    "    from huggingface_hub import login\n",
    "    \n",
    "    # Prompt the user for their Hugging Face token\n",
    "    token = input(\"Enter your Hugging Face access token: \")\n",
    "    login(token=token)\n",
    "\n",
    "    # Load the tokenizer and model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=True)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name, use_auth_token=True)\n",
    "    print(f\"Model '{model_name}' and tokenizer successfully loaded locally.\")\n",
    "    return tokenizer, model\n",
    "\n",
    "# Specify the Hugging Face model\n",
    "model_name = \"meta-llama/Llama-2-7b-hf\"\n",
    "tokenizer, model = authenticate_and_download_model(model_name)\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "data = pd.read_csv('/opt/app-root/src/models/data/diabetes.csv')\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = data.drop('Outcome', axis=1)\n",
    "y = data['Outcome']\n",
    "\n",
    "# Train, validation, and test split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "X_validation, X_test, y_validation, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=0)\n",
    "\n",
    "# Convert data into PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train.values)\n",
    "y_train_tensor = torch.LongTensor(y_train.values)\n",
    "X_validation_tensor = torch.FloatTensor(X_validation.values)\n",
    "y_validation_tensor = torch.LongTensor(y_validation.values)\n",
    "\n",
    "# Create DataLoader for batching\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "validation_dataset = TensorDataset(X_validation_tensor, y_validation_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=32)\n",
    "\n",
    "# Define the neural network architecture\n",
    "class DiabetesModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiabetesModel, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(8, 20)\n",
    "        self.fc2 = torch.nn.Linear(20, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "torch.manual_seed(10)\n",
    "model = DiabetesModel()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# TensorBoard setup\n",
    "log_dir = \"logs/training/\" + datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "writer = SummaryWriter(log_dir)\n",
    "\n",
    "# Training loop\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(X_batch)\n",
    "        loss = criterion(predictions, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    validation_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in validation_loader:\n",
    "            predictions = model(X_batch)\n",
    "            loss = criterion(predictions, y_batch)\n",
    "            validation_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted_classes = torch.max(predictions, 1)\n",
    "            correct_predictions += (predicted_classes == y_batch).sum().item()\n",
    "            total_predictions += y_batch.size(0)\n",
    "\n",
    "    # Calculate average losses and accuracy\n",
    "    train_loss /= len(train_loader)\n",
    "    validation_loss /= len(validation_loader)\n",
    "    validation_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    # Log metrics to TensorBoard\n",
    "    writer.add_scalar(\"Loss/Train\", train_loss, epoch)\n",
    "    writer.add_scalar(\"Loss/Validation\", validation_loss, epoch)\n",
    "    writer.add_scalar(\"Accuracy/Validation\", validation_accuracy, epoch)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}: \"\n",
    "          f\"Train Loss = {train_loss:.4f}, Validation Loss = {validation_loss:.4f}, \"\n",
    "          f\"Validation Accuracy = {validation_accuracy:.4f}\")\n",
    "\n",
    "# Close the TensorBoard writer\n",
    "writer.close()\n",
    "\n",
    "# Print instructions for TensorBoard\n",
    "print(f\"Training complete. To view TensorBoard, run the following command:\")\n",
    "print(f\"tensorboard --logdir={log_dir}\")\n",
    "\n",
    "# Exporting the model to ONNX format and saving it locally\n",
    "onnx_file_path = \"./meta-llama-7b_model.onnx\"\n",
    "dummy_input = torch.randn(1, 8)  # Dummy input with the same feature dimensions\n",
    "torch.onnx.export(\n",
    "    model, \n",
    "    dummy_input, \n",
    "    onnx_file_path, \n",
    "    export_params=True, \n",
    "    opset_version=12, \n",
    "    do_constant_folding=True, \n",
    "    input_names=[\"input\"], \n",
    "    output_names=[\"output\"], \n",
    "    dynamic_axes={\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}}\n",
    ")\n",
    "\n",
    "print(f\"ONNX model exported successfully and saved at '{onnx_file_path}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "190af1c9-9c2f-4ca6-bedc-f9fd57a4f2f5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.47.0-py3-none-any.whl (10.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting regex!=2019.12.17\n",
      "  Downloading regex-2024.11.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (780 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.9/780.9 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/app-root/lib/python3.9/site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting safetensors>=0.4.1\n",
      "  Downloading safetensors-0.4.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (436 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.1/436.1 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/app-root/lib/python3.9/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: filelock in /opt/app-root/lib/python3.9/site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/app-root/lib/python3.9/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/app-root/lib/python3.9/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/app-root/lib/python3.9/site-packages (from transformers) (4.66.5)\n",
      "Collecting huggingface-hub<1.0,>=0.24.0\n",
      "  Downloading huggingface_hub-0.26.3-py3-none-any.whl (447 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.6/447.6 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/app-root/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/app-root/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/app-root/lib/python3.9/site-packages (from requests->transformers) (2024.7.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/app-root/lib/python3.9/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/app-root/lib/python3.9/site-packages (from requests->transformers) (1.26.19)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/app-root/lib/python3.9/site-packages (from requests->transformers) (3.8)\n",
      "Installing collected packages: safetensors, regex, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.26.3 regex-2024.11.6 safetensors-0.4.5 tokenizers-0.21.0 transformers-4.47.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05c4cf7-de87-4119-aae1-866d23b99e2c",
   "metadata": {},
   "source": [
    "## Uploading ONNX Model file to an S3-Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb5143cf-e795-480f-a134-13a4d2b3ab92",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 bucket 'openshift-ai-bucket' connected successfully.\n",
      "File './meta-llama-7b_model.onnx' uploaded to S3 bucket 'openshift-ai-bucket' successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.9/site-packages/urllib3/connectionpool.py:1063: InsecureRequestWarning: Unverified HTTPS request is being made to host '172.17.66.103'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## Dell-APEX\n",
    "\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "# Specify the ONNX model file name and S3 bucket details\n",
    "onnx_file_name = \"./meta-llama-7b_model.onnx\"\n",
    "bucket_name = os.getenv(\"AWS_S3_BUCKET\")\n",
    "endpoint_url = \"https://172.17.66.103\"  # Update this to your S3 endpoint URL\n",
    "\n",
    "# Fetch AWS credentials from environment variables\n",
    "aws_access_key_id = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "aws_secret_access_key = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "\n",
    "# Initialize the S3 client\n",
    "try:\n",
    "    s3_client = boto3.client(\n",
    "        \"s3\",\n",
    "        aws_access_key_id=aws_access_key_id,\n",
    "        aws_secret_access_key=aws_secret_access_key,\n",
    "        endpoint_url=endpoint_url,\n",
    "        verify=False  # Disable SSL verification for custom S3 endpoints\n",
    "    )\n",
    "    print(f\"S3 bucket '{bucket_name}' connected successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to connect to S3: {e}\")\n",
    "    raise\n",
    "\n",
    "# Upload the ONNX model to the S3 bucket\n",
    "try:\n",
    "    s3_client.upload_file(onnx_file_name, bucket_name, os.path.basename(onnx_file_name))\n",
    "    print(f\"File '{onnx_file_name}' uploaded to S3 bucket '{bucket_name}' successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to upload file: {e}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beb72455-1008-4bdb-8b09-e94d1536782c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to S3 bucket 'openshift-ai-bucket' successfully.\n",
      "Available files in the S3 bucket 'openshift-ai-bucket':\n",
      "- models/\n",
      "- models/meta-llama-7b_model.onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.9/site-packages/urllib3/connectionpool.py:1063: InsecureRequestWarning: Unverified HTTPS request is being made to host '172.17.66.103'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## Dell-APEX - To get Available objets in S3\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "# Specify S3 bucket details\n",
    "bucket_name = os.getenv(\"AWS_S3_BUCKET\")\n",
    "endpoint_url = \"https://172.17.66.103\"  # Update this to your S3 endpoint URL\n",
    "\n",
    "# Fetch AWS credentials from environment variables\n",
    "aws_access_key_id = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "aws_secret_access_key = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "\n",
    "# Initialize the S3 client\n",
    "try:\n",
    "    s3_client = boto3.client(\n",
    "        \"s3\",\n",
    "        aws_access_key_id=aws_access_key_id,\n",
    "        aws_secret_access_key=aws_secret_access_key,\n",
    "        endpoint_url=endpoint_url,\n",
    "        verify=False  # Disable SSL verification for custom S3 endpoints\n",
    "    )\n",
    "    print(f\"Connected to S3 bucket '{bucket_name}' successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to connect to S3: {e}\")\n",
    "    raise\n",
    "\n",
    "# List available files in the S3 bucket\n",
    "try:\n",
    "    response = s3_client.list_objects_v2(Bucket=bucket_name)\n",
    "    if 'Contents' in response:\n",
    "        print(f\"Available files in the S3 bucket '{bucket_name}':\")\n",
    "        for obj in response['Contents']:\n",
    "            print(f\"- {obj['Key']}\")\n",
    "    else:\n",
    "        print(f\"The S3 bucket '{bucket_name}' is empty.\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to list files in the bucket: {e}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcaffc46-e6a6-470b-a923-836085169dd7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 bucket 'ocp-ai-bucket' connected successfully.\n",
      "File './meta-llama-7b_model.onnx' uploaded to S3 bucket 'ocp-ai-bucket' successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.9/site-packages/urllib3/connectionpool.py:1063: InsecureRequestWarning: Unverified HTTPS request is being made to host 'minio-api-minio.apps.ocpbmai.sdxtest.local'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## Minio-s3\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "# Specify the ONNX model file name and S3 bucket details\n",
    "onnx_file_name = \"./meta-llama-7b_model.onnx\"\n",
    "bucket_name = os.getenv(\"AWS_S3_BUCKET\")\n",
    "endpoint_url = \"https://minio-api-minio.apps.ocpbmai.sdxtest.local\"  # Update this to your S3 endpoint URL\n",
    "\n",
    "# Fetch AWS credentials from environment variables\n",
    "aws_access_key_id = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "aws_secret_access_key = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "\n",
    "# Initialize the S3 client\n",
    "try:\n",
    "    s3_client = boto3.client(\n",
    "        \"s3\",\n",
    "        aws_access_key_id=aws_access_key_id,\n",
    "        aws_secret_access_key=aws_secret_access_key,\n",
    "        endpoint_url=endpoint_url,\n",
    "        verify=False  # Disable SSL verification for custom S3 endpoints\n",
    "    )\n",
    "    print(f\"S3 bucket '{bucket_name}' connected successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to connect to S3: {e}\")\n",
    "    raise\n",
    "\n",
    "# Upload the ONNX model to the S3 bucket\n",
    "try:\n",
    "    s3_client.upload_file(onnx_file_name, bucket_name, os.path.basename(onnx_file_name))\n",
    "    print(f\"File '{onnx_file_name}' uploaded to S3 bucket '{bucket_name}' successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to upload file: {e}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d561f5d-18c0-4c27-bffe-c88f0005e1d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
